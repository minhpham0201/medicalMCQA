{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pyodbc import connect\n",
    "from deep_translator import GoogleTranslator\n",
    "from pandas import DataFrame, read_csv\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNC cleanNumber\n",
    "def cleanNumber(text):\n",
    "    s = re.sub('(\\(\\d+\\))', '', text)\n",
    "    return re.sub('\\s+\\.\\s+', '. ', s).strip()\n",
    "def cleanFirstNumber(text):\n",
    "    text = cleanNumber(text)\n",
    "    return re.sub('^\\d+\\.\\s*', '', text).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNC fetchAll, saveMany of SQL\n",
    "def fetchAll(sql, parameters = None):\n",
    "    db = connect('Driver={SQL Server};Server=.;Database=Hospital;UID=sa;PWD=123')\n",
    "    try:\n",
    "        cursor = db.cursor()\n",
    "        if parameters:\n",
    "            cursor.execute(sql, parameters)\n",
    "        else:\n",
    "            cursor.execute(sql)\n",
    "        return cursor.fetchall()\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "        return False\n",
    "    finally:\n",
    "        cursor.close()\n",
    "        db.close()      \n",
    "def saveMany(sql, arr):\n",
    "    db = connect('Driver={SQL Server};Server=.;Database=Hospital;UID=sa;PWD=123')\n",
    "    try:\n",
    "        cursor = db.cursor()\n",
    "        cursor.executemany(sql, arr)\n",
    "        ret = cursor.rowcount\n",
    "        db.commit()\n",
    "        return True\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "        return False\n",
    "    finally:\n",
    "        cursor.close()\n",
    "        db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNC translate_text\n",
    "def translate_text(text):\n",
    "    translator = GoogleTranslator(source='vi', target='en')\n",
    "    try:\n",
    "        return translator.translate(text)\n",
    "    except Exception as e:\n",
    "        return \"Error: \" + str(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELECT DATA\n",
    "sql = '''\n",
    "select Url,FieldEn,ArticleEn,Item.ItemId, ItemEn, ContentEn from Item \n",
    "join Paragraph on Item.ItemId = Paragraph.ItemId \n",
    "join Article on Article.ArticleId=Item.ArticleId\n",
    "join Field on Field.FieldId = Article.FieldId\n",
    "WHERE IsDeleted = 0\n",
    "ORDER BY Paragraph.ParagraphId\n",
    "'''\n",
    "data = fetchAll(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GO merge paragraph MERGE THEO M·ªêC 430 WORDS\n",
    "def merge_paragraphs(data):\n",
    "    dataset = []\n",
    "    d = {'Url': data[0][0], 'FieldEn': data[0][1], 'ArticleEn': data[0][2], 'ItemEn': data[0][4], 'ContentEn': cleanFirstNumber(data[0][-1])}\n",
    "    cnt = len(cleanFirstNumber(data[0][-1]).split())\n",
    "    for i in range(1, len(data)):\n",
    "        length = len(cleanFirstNumber(data[i][-1]).split())\n",
    "        if data[i][2] == data[i-1][2]:\n",
    "            if cnt + length < 430:\n",
    "                d['ContentEn'] += cleanFirstNumber(data[i][-1])\n",
    "            else:\n",
    "                dataset.append(d)\n",
    "                cnt = 0\n",
    "                d = {'Url': data[i][0], 'FieldEn': data[0][1], 'ArticleEn': data[i][2], 'ItemEn': data[i][4], 'ContentEn': cleanFirstNumber(data[i][-1])}\n",
    "        else:\n",
    "            dataset.append(d)\n",
    "            cnt = 0\n",
    "            d = {'Url': data[i][0], 'FieldEn': data[0][1], 'ArticleEn': data[i][2], 'ItemEn': data[i][4], 'ContentEn': cleanFirstNumber(data[i][-1])}\n",
    "        cnt += length\n",
    "    dataset.append(d)\n",
    "    return dataset\n",
    "dataset = merge_paragraphs(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DataFrame(dataset)\n",
    "df['Content_Length'] = df['ContentEn'].str.split().map(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "break430 = df\n",
    "break430['Combined_Content_2'] = break430['ItemEn'].astype(str) + ' ' + break430['ContentEn']\n",
    "break430['Combined_Length_2'] = break430['Combined_Content_2'].str.split().map(len)\n",
    "combined_title = break430.drop(columns=['FieldEn', 'ArticleEn', 'ItemEn', 'ContentEn', 'Content_Length'])\n",
    "combined_title.sort_values('Combined_Length_2',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_title.to_csv('data_break430_231110.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
